{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25d7736c-ba17-4aff-b6bb-66eba20fbf4e",
   "metadata": {
    "id": "25d7736c-ba17-4aff-b6bb-66eba20fbf4e"
   },
   "source": [
    "# Lab | Data Structuring and Combining Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2cdfc70-44c8-478c-81e7-2bc43fdf4986",
   "metadata": {
    "id": "a2cdfc70-44c8-478c-81e7-2bc43fdf4986"
   },
   "source": [
    "## Challenge 1: Combining & Cleaning Data\n",
    "\n",
    "In this challenge, we will be working with the customer data from an insurance company, as we did in the two previous labs. The data can be found here:\n",
    "- https://raw.githubusercontent.com/data-bootcamp-v4/data/main/file1.csv\n",
    "\n",
    "But this time, we got new data, which can be found in the following 2 CSV files located at the links below.\n",
    "\n",
    "- https://raw.githubusercontent.com/data-bootcamp-v4/data/main/file2.csv\n",
    "- https://raw.githubusercontent.com/data-bootcamp-v4/data/main/file3.csv\n",
    "\n",
    "Note that you'll need to clean and format the new data.\n",
    "\n",
    "Observation:\n",
    "- One option is to first combine the three datasets and then apply the cleaning function to the new combined dataset\n",
    "- Another option would be to read the clean file you saved in the previous lab, and just clean the two new files and concatenate the three clean datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "492d06e3-92c7-4105-ac72-536db98d3244",
   "metadata": {
    "id": "492d06e3-92c7-4105-ac72-536db98d3244"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_1 = pd.read_csv('https://raw.githubusercontent.com/data-bootcamp-v4/data/main/file1.csv')\n",
    "df_2 = pd.read_csv('https://raw.githubusercontent.com/data-bootcamp-v4/data/main/file2.csv')\n",
    "df_3 = pd.read_csv('https://raw.githubusercontent.com/data-bootcamp-v4/data/main/file3.csv')\n",
    "\n",
    "for df in [df_1, df_2, df_3]:\n",
    "    display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600ce5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# renaming columns\n",
    "for df in [df_1, df_2, df_3]:\n",
    "    df.rename(columns=lambda x: x.replace(' ', '_').lower(), inplace=True)\n",
    "    df.rename(columns={'st': 'state'}, inplace=True)\n",
    "\n",
    "display(df_1, df_2, df_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2601e912",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate the three dataframes\n",
    "df = pd.concat([df_1, df_2, df_3])\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238e0145",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# replace values\n",
    "import re\n",
    "\n",
    "def replace_values(value, replacements):\n",
    "    if isinstance(value, str):\n",
    "        for pattern in replacements:\n",
    "            value = re.sub(pattern[0], pattern[1], value)\n",
    "        return value\n",
    "    return value\n",
    "\n",
    "df['gender'] = df['gender'].apply(replace_values, args=[[['female|Femal', 'F'], ['Male', 'M']]])\n",
    "df['state'] = df['state'].apply(replace_values, args=[[[r'Cali$', 'California'], ['WA', 'Washington'], ['AZ', 'Arizona']]])\n",
    "df['education'] = df['education'].apply(replace_values, args=[[[r'Bachelors$', 'Bachelor']]])\n",
    "df['customer_lifetime_value'] = df['customer_lifetime_value'].apply(replace_values, args=[[[r'%', '']]])\n",
    "df['vehicle_class'] = df['vehicle_class'].apply(replace_values, args=[[[r'Sports.*|Luxury.*', 'Luxury']]])\n",
    "\n",
    "# fill nas\n",
    "df['number_of_open_complaints'] = df['number_of_open_complaints'].apply(replace_values, args=[[[r'\\d+/(\\d+)/\\d+', r'\\1']]])\n",
    "df['number_of_open_complaints'] = df['number_of_open_complaints'].fillna(0)\n",
    "\n",
    "# recast data types\n",
    "data_types = {'customer': 'object',\n",
    "          'state': 'category', \n",
    "          'gender': 'category', \n",
    "          'education': 'category', \n",
    "          'customer_lifetime_value': 'float', \n",
    "          'income': 'float',\n",
    "          'monthly_premium_auto': 'float', \n",
    "          'number_of_open_complaints': 'int', \n",
    "          'policy_type': 'category', \n",
    "          'vehicle_class': 'category', \n",
    "          'total_claim_amount': 'float'}\n",
    "\n",
    "df = df.astype(data_types)\n",
    "\n",
    "# remove nulls\n",
    "\n",
    "df= df.dropna(subset=['customer'])\n",
    "\n",
    "# Fill categorical columns with the value 'Unknown'\n",
    "categorical_cols = df.select_dtypes(include=['category']).columns\n",
    "df[categorical_cols] = df[categorical_cols].astype('object')\n",
    "df[categorical_cols] = df[categorical_cols].fillna('Unknown')\n",
    "df[categorical_cols] = df[categorical_cols].astype('category') \n",
    "\n",
    "# Fill life time value, income and monthly premium auto with the mean\n",
    "df['customer_lifetime_value'] = df['customer_lifetime_value'].fillna(df['customer_lifetime_value'].mean())\n",
    "df['income'] = df['income'].fillna(df['income'].mean())\n",
    "df['monthly_premium_auto'] = df['monthly_premium_auto'].fillna(df['monthly_premium_auto'].mean())\n",
    "\n",
    "#Fill Total Claim Amount with 0\n",
    "df['total_claim_amount'] = df['total_claim_amount'].fillna(0)\n",
    "\n",
    "\n",
    "# remove duplicates\n",
    "\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "df.drop_duplicates(subset=['customer'], keep='first', inplace=True)\n",
    "\n",
    "df.head(500)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b8a9e7-7db9-4604-991b-ef6771603e57",
   "metadata": {
    "id": "31b8a9e7-7db9-4604-991b-ef6771603e57"
   },
   "source": [
    "# Challenge 2: Structuring Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a877fd6d-7a0c-46d2-9657-f25036e4ca4b",
   "metadata": {
    "id": "a877fd6d-7a0c-46d2-9657-f25036e4ca4b"
   },
   "source": [
    "In this challenge, we will continue to work with customer data from an insurance company, but we will use a dataset with more columns, called marketing_customer_analysis.csv, which can be found at the following link:\n",
    "\n",
    "https://raw.githubusercontent.com/data-bootcamp-v4/data/main/marketing_customer_analysis_clean.csv\n",
    "\n",
    "This dataset contains information such as customer demographics, policy details, vehicle information, and the customer's response to the last marketing campaign. Our goal is to explore and analyze this data by performing data cleaning, formatting, and structuring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa10d9b0-1c27-4d3f-a8e4-db6ab73bfd26",
   "metadata": {
    "id": "aa10d9b0-1c27-4d3f-a8e4-db6ab73bfd26"
   },
   "outputs": [],
   "source": [
    "df_mkt = pd.read_csv('https://raw.githubusercontent.com/data-bootcamp-v4/data/main/marketing_customer_analysis_clean.csv')\n",
    "df_mkt.head()\n",
    "df_mkt.columns "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df35fd0d-513e-4e77-867e-429da10a9cc7",
   "metadata": {
    "id": "df35fd0d-513e-4e77-867e-429da10a9cc7"
   },
   "source": [
    "1. You work at the marketing department and you want to know which sales channel brought the most sales in terms of total revenue. Using pivot, create a summary table showing the total revenue for each sales channel (branch, call center, web, and mail).\n",
    "Round the total revenue to 2 decimal points.  Analyze the resulting table to draw insights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5317b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pivot_table = df_mkt.pivot_table(values='total_claim_amount', index='sales_channel', aggfunc='sum')\n",
    "\n",
    "pivot_table = pivot_table.round(2)\n",
    "\n",
    "display(pivot_table)\n",
    "\n",
    "max_revenue_channel = pivot_table['total_claim_amount'].idxmax()\n",
    "max_revenue = pivot_table['total_claim_amount'].max()\n",
    "\n",
    "print(f\"Best channel : {max_revenue_channel} with ${max_revenue} of revenue.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "640993b2-a291-436c-a34d-a551144f8196",
   "metadata": {
    "id": "640993b2-a291-436c-a34d-a551144f8196"
   },
   "source": [
    "2. Create a pivot table that shows the average customer lifetime value per gender and education level. Analyze the resulting table to draw insights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22e0f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_pivot_table = df_mkt.pivot_table(values='customer_lifetime_value', index=['gender','education'], aggfunc='mean')\n",
    "display(clf_pivot_table)\n",
    "\n",
    "max_clv = clf_pivot_table.max().max()\n",
    "max_clv_id = clf_pivot_table.idxmax().max()\n",
    "print(max_clv_id)\n",
    "print(f\"Max Customer Lifetime Value : {max_clv_id} with ${max_clv}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c7f2e5-3d90-43e5-be33-9781b6069198",
   "metadata": {
    "id": "32c7f2e5-3d90-43e5-be33-9781b6069198"
   },
   "source": [
    "## Bonus\n",
    "\n",
    "You work at the customer service department and you want to know which months had the highest number of complaints by policy type category. Create a summary table showing the number of complaints by policy type and month.\n",
    "Show it in a long format table."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d09a8f-953c-448a-a5f8-2e5a8cca7291",
   "metadata": {
    "id": "e3d09a8f-953c-448a-a5f8-2e5a8cca7291"
   },
   "source": [
    "*In data analysis, a long format table is a way of structuring data in which each observation or measurement is stored in a separate row of the table. The key characteristic of a long format table is that each column represents a single variable, and each row represents a single observation of that variable.*\n",
    "\n",
    "*More information about long and wide format tables here: https://www.statology.org/long-vs-wide-data/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a069e0b-b400-470e-904d-d17582191be4",
   "metadata": {
    "id": "3a069e0b-b400-470e-904d-d17582191be4"
   },
   "outputs": [],
   "source": [
    "# Your code goes here\n",
    "complaints_pivot_table = df_mkt.pivot_table(values='number_of_open_complaints', index=['month', 'policy_type'], aggfunc='sum').reset_index()\n",
    "complaints_pivot_table = complaints_pivot_table.sort_values(by='number_of_open_complaints', ascending=False)\n",
    "display(complaints_pivot_table)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
